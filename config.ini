# We will use this config to make iterating the training much easier,
# you can find all the relevant tunable parameters for the project 

[testing]
testing = 0
data_samples_for_testing = 1000

[callbacks]
neptune_logger = 0
neptune_project = "BirdClefHomework/csipcsirip"
neptune_token = ""
model_checkpoint = 0
model_checkpoint_type = 'accuracy' # 'accuracy', 'loss'
model_checkpoint_verbose = 0

[paths]
model_name = "model.pth"
model_path = "models/"
labeled = "data/train_audio"
metadata = "data/train_metadata.csv"
model_checkpoint_path = "models/model_checkpoint/checkpoint.pth"

[trainer]
seed = 42
batch_size_train = 10
batch_size_val = 10
batch_size_test = 10
num_workers = 6
n_epochs = 3

[agent]
lr_decay = 1 
lr_decay_type = "cos" # lin, exp, cos, warmupcosine
lr_start = 0.01
lr_warmup_end = 0.01
lr_end = 0.00005
exp_gamma = 0.97
lr_verbose = 0
loss = "cross_entropy" # cross_entropy, focal_loss
optimizer = "adam" # sgd, adam, rmsprop

[model]
type = "mobilenet_v3_small" # mobilenet_v3_small, mobilenet_v3_large, efficientnet_v2_s, efficientnet_v2_m, efficientnet_v2_l - might not work, 
transfer_learning = 1

[data]
hash_path = "processed_data/"
train_ratio = 0.8
test_val_ratio = 0.5
min_samples_in_class = 150
shuffle = 1
output_dir = "processed_data/"
num_workers = 14
multi_threading = 0

[data_process]
sample_rate = 32000
n_mels = 250
n_fft = 2048
hop_length = 512
max_length_s = 15
f_max = 16000
f_min = 20
mode = 'single' # slice or single

[augmentation]
data_augmentation = 1
augment_add_noise = 0
augment_spec_augment = 1
